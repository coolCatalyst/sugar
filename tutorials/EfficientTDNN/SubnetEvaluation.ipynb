{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-viking",
   "metadata": {},
   "source": [
    "# Subnet Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loved-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random, warnings, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "sys.path.append('/workspace/projects')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sugar.transforms import LogMelFbanks\n",
    "from sugar.models.dynamictdnn import tdnn8m2g\n",
    "from sugar.models import SpeakerModel, WrappedModel, veri_validate, batch_forward\n",
    "from sugar.database import Utterance, AugmentedUtterance\n",
    "from sugar.data.voxceleb1 import veriset\n",
    "from sugar.data.voxceleb2 import veritrain\n",
    "from sugar.data.augmentation import augset\n",
    "from sugar.scores import score_cohorts, asnorm\n",
    "from sugar.vectors import extract_vectors\n",
    "from sugar.metrics import calculate_mindcf, calculate_eer\n",
    "from sugar.utils.utility import bn_state_dict, load_bn_state_dict\n",
    "\n",
    "def eval_veri(test_loader, network, p_target=0.01, device=\"cpu\", vectors=None):\n",
    "    eer, dcf, vec, scs = veri_validate(test_loader, network, p_target=p_target, device=device, ret_info=True, vectors=vectors)\n",
    "    scs = pandas.DataFrame({'score': scs, 'enroll': test_loader.dataset.enrolls, 'test': test_loader.dataset.tests})\n",
    "    labs = test_loader.dataset.labels\n",
    "    eer = eer[0] * 100\n",
    "    dcf = dcf[0]\n",
    "    return eer, dcf, vec, scs\n",
    "\n",
    "def eval_asnorm(labs, vec, scs, cohorts, p_target=0.01):\n",
    "    cohorts_o = score_cohorts(cohorts, vec)\n",
    "    asso = asnorm(scs, cohorts_o)\n",
    "    eer_o_asnorm = calculate_eer(labs, asso)[0] * 100\n",
    "    dcf_o_asnorm = calculate_mindcf(labs, asso, p_target=p_target)[0]\n",
    "    return eer_o_asnorm, dcf_o_asnorm\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-alcohol",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "- Train set\n",
    "- Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5df020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vox1_root = \"/path/to/voxceleb1/\"\n",
    "# vox2_root = \"/path/to/voxceleb2/\"\n",
    "\n",
    "vox1_root = \"/workspace/datasets/voxceleb/voxceleb1/\"\n",
    "vox2_root = \"/workspace/datasets/voxceleb/voxceleb2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mysterious-malaysia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of speakers is 5994\n"
     ]
    }
   ],
   "source": [
    "# vox2_train = '/path/to/train_list.txt'\n",
    "vox2_train = '/workspace/datasets/voxceleb/Vox2/train_list.txt'\n",
    "train, spks = veritrain(vox2_train, rootdir=vox2_root, num_samples=64000)\n",
    "\n",
    "random.shuffle(train.datalst)\n",
    "train.datalst = train.datalst[:6000]\n",
    "\n",
    "aug_wav = augset(num_samples=64000)\n",
    "trainset = AugmentedUtterance(train, spks, augment=aug_wav, mode='v2+')\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=5, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "084e51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "veritesto = \"veri_test2.txt\"\n",
    "veri_testo, veri_teste, veri_testh, wav_files = veriset(\n",
    "    test2=veritesto, all2=None, hard2=None, rootdir=vox1_root, num_samples=64000, num_eval=2)\n",
    "testo_loader = DataLoader(veri_testo, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c06a9",
   "metadata": {},
   "source": [
    "## Evaluate different subnets\n",
    "\n",
    "- $a_\\text{max}$: (4, [512, 512, 512, 512, 512], [5, 5, 5, 5, 5], 1536)\n",
    "- $a_\\text{Kmin}$: (4, [512, 512, 512, 512, 512], [1, 1, 1, 1, 1], 1536)\n",
    "- $a_\\text{Dmin}$: (2, [512, 512, 512], [1, 1, 1], 1536)\n",
    "- $a_\\text{C1min}$: (2, [256, 256, 256], [1, 1, 1], 768)\n",
    "- $a_\\text{C2min}$: (2, [128, 128, 128], [1, 1, 1], 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229878fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['module.__L__.W'])\n"
     ]
    }
   ],
   "source": [
    "transform = LogMelFbanks(80)\n",
    "modelarch = tdnn8m2g(80, 192)\n",
    "model = SpeakerModel(modelarch, transform=transform)\n",
    "model = WrappedModel(model)\n",
    "\n",
    "# supernet_path = '/path/to/supernet_checkpoint'\n",
    "# supernet_path = '/workspace/projects/sugar/examples/nas/exps/exp3/supernet_kernel_width1_width2_depth/checkpoint000064.pth.tar'\n",
    "supernet_path = '/workspace/projects/sugar/examples/nas/exps/exp3/supernet_depth_kernel_width1_width2/checkpoint000064.pth.tar'\n",
    "state_dict = torch.load(supernet_path, map_location='cpu')\n",
    "print(model.load_state_dict(state_dict['state_dict'], strict=False))\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "import copy\n",
    "model_bak = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec189126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forward Model: 100%|██████████| 187/187 [00:08<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved batch norm state dict /workspace/projects/sugar/examples/nas/exps/exp3/supernet_depth_kernel_width1_width2/(4, [512, 512, 512, 512, 512], [1, 1, 1, 1, 1], 1536).bn.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract Vectors: 100%|██████████| 4708/4708 [01:20<00:00, 58.41it/s]\n",
      "Compute Scores: 100%|██████████| 37611/37611 [00:06<00:00, 6011.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subnet: (4, [512, 512, 512, 512, 512], [1, 1, 1, 1, 1], 1536)\n",
      "Evaluate on Vox1-O: * EER / DCF 3.37% / 0.326\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    (4, [512, 512, 512, 512, 512], [5, 5, 5, 5, 5], 1536),\n",
    "    (4, [512, 512, 512, 512, 512], [1, 1, 1, 1, 1], 1536),\n",
    "    (2, [512, 512, 512], [1, 1, 1], 1536),\n",
    "    (2, [256, 256, 256], [1, 1, 1], 768),\n",
    "    (2, [128, 128, 128], [1, 1, 1], 384),\n",
    "]\n",
    "\n",
    "for config in configs[1:2]:\n",
    "    model.module.__S__ = model_bak.module.__S__.clone(config)\n",
    "    bn_path = os.path.join(os.path.dirname(supernet_path), f\"{config}.bn.pth\")\n",
    "    if os.path.exists(bn_path):\n",
    "        load_bn_state_dict(model.module.__S__, torch.load(bn_path, map_location=\"cpu\"))\n",
    "        print(f\"loaded state dict from saved batch norm {bn_path}\")\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        batch_forward(train_loader, model, device=device)\n",
    "        torch.save(bn_state_dict(model.module.__S__), bn_path)\n",
    "        print(f\"saved batch norm state dict {bn_path}\")\n",
    "        time.sleep(1)\n",
    "    eero, dcfo, veco, scso = eval_veri(testo_loader, model, device=device)\n",
    "    print(f'subnet: {config}\\nEvaluate on Vox1-O: * EER / DCF {eero:.2f}% / {dcfo:.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cb5e4",
   "metadata": {},
   "source": [
    "## Results among different progressive orders\n",
    "\n",
    "### Subnets\n",
    "\n",
    "- $a_\\text{max}$: (4, [512, 512, 512, 512, 512], [5, 5, 5, 5, 5], 1536)\n",
    "- $a_\\text{Kmin}$: (4, [512, 512, 512, 512, 512], [1, 1, 1, 1, 1], 1536)\n",
    "- $a_\\text{Dmin}$: (2, [512, 512, 512], [1, 1, 1], 1536)\n",
    "- $a_\\text{C1min}$: (2, [256, 256, 256], [1, 1, 1], 768)\n",
    "- $a_\\text{C2min}$: (2, [128, 128, 128], [1, 1, 1], 384)\n",
    "\n",
    "### Supernets\n",
    "\n",
    "- kernel->depth->width: /workspace/projects/sugar/examples/nas/exps/exp3/width2/phase2/width2.torchparams\n",
    "- kernel->width->depth: /workspace/projects/sugar/examples/nas/exps/exp3/supernet_kernel_width1_width2_depth/checkpoint000064.pth.tar\n",
    "- depth->kernel->width: /workspace/projects/sugar/examples/nas/exps/exp3/supernet_depth_kernel_width1_width2/checkpoint000064.pth.tar\n",
    "\n",
    "| Progressive Order | $a_\\text{max}$ | $a_\\text{Kmin}$ | $a_\\text{Dmin}$ | $a_\\text{C1min}$ | $a_\\text{C2min}$ |\n",
    "|:---|:---:|:---:|:---:|:---:|:---:|\n",
    "| Table V kernel->depth->width | 1.44 / 0.163 | 3.54 / 0.344 | 3.58 / 0.334 | 3.98 / 0.360 | 5.29 / 0.478 |\n",
    "| kernel->width->depth | 1.49 / 0.153 | 3.52 / 0.330 | 3.82 / 0.369 | 3.99 / 0.373 | 5.32 / 0.463 |\n",
    "| depth->kernel->width | 1.48 / 0.144 | 3.43 / 0.325 | 3.56 / 0.328 | 3.99 / 0.389 | 5.39 / 0.474 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6811c3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
